{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'sms+spam+collection/SMSSpamCollection'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing spam label('spam') to 1 and non-spam label('ham') to 0\n",
    "df['label'] = df['label'].replace({'spam': 1, 'ham': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  go until jurong point, crazy.. available only ...\n",
       "1      0                      ok lar... joking wif u oni...\n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      0  u dun say so early hor... u c already then say...\n",
       "4      0  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting messages to lowercases since for instance 'N' is computationally != 'n'\n",
    "df['message'] = df['message'].apply(lambda a: a.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will ü b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing url's from messages\n",
    "df['message'] = df['message'].str.replace(r'http\\S+', '', regex=True)\n",
    "\n",
    "df['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**\n",
    "* splitting each message to individual words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ATTAH KUMAH\n",
      "[nltk_data]     MENSAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\ATTAH KUMAH\n",
      "[nltk_data]     MENSAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_message(messages):\n",
    "    \"\"\"\n",
    "    tokenize each message to split words so they stand on their own\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "\n",
    "    tokenized_words = word_tokenize(messages)\n",
    "    tokens.extend(tokenized_words)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "df['tokenized'] = df['message'].apply(tokenize_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, ,, crazy, .., avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>[freemsg, hey, there, darling, it, 's, been, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>[as, per, your, request, 'melle, melle, (, oru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "      <td>[winner, !, !, as, a, valued, network, custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "      <td>[had, your, mobile, 11, months, or, more, ?, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  go until jurong point, crazy.. available only ...   \n",
       "1      0                      ok lar... joking wif u oni...   \n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      0  u dun say so early hor... u c already then say...   \n",
       "4      0  nah i don't think he goes to usf, he lives aro...   \n",
       "5      1  freemsg hey there darling it's been 3 week's n...   \n",
       "6      0  even my brother is not like to speak with me. ...   \n",
       "7      0  as per your request 'melle melle (oru minnamin...   \n",
       "8      1  winner!! as a valued network customer you have...   \n",
       "9      1  had your mobile 11 months or more? u r entitle...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [go, until, jurong, point, ,, crazy, .., avail...  \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, ..., u, c, alrea...  \n",
       "4  [nah, i, do, n't, think, he, goes, to, usf, ,,...  \n",
       "5  [freemsg, hey, there, darling, it, 's, been, 3...  \n",
       "6  [even, my, brother, is, not, like, to, speak, ...  \n",
       "7  [as, per, your, request, 'melle, melle, (, oru...  \n",
       "8  [winner, !, !, as, a, valued, network, custome...  \n",
       "9  [had, your, mobile, 11, months, or, more, ?, u...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenized data to saved-data/tokenized_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the tokenized dataframe\n",
    "\n",
    "file_path = 'saved-data/tokenized_data.csv'\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f'Saved tokenized data to {file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing common `stopwords` such as \"the,\" \"is,\" \"and,\" etc., which do not carry significant meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenize_message):\n",
    "    \"\"\"\n",
    "    removes words that do not have meanings from the tokenized messages\n",
    "    \"\"\"\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in tokenize_message if word not in stop_word]\n",
    "\n",
    "    return filtered_words\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, jurong, point, ,, crazy, .., available, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, ..., u, c, already, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, n't, think, goes, usf, ,, lives, around,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>[freemsg, hey, darling, 's, 3, week, 's, word,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, brother, like, speak, ., treat, like, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>[per, request, 'melle, melle, (, oru, minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "      <td>[winner, !, !, valued, network, customer, sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "      <td>[mobile, 11, months, ?, u, r, entitled, update...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  go until jurong point, crazy.. available only ...   \n",
       "1      0                      ok lar... joking wif u oni...   \n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      0  u dun say so early hor... u c already then say...   \n",
       "4      0  nah i don't think he goes to usf, he lives aro...   \n",
       "5      1  freemsg hey there darling it's been 3 week's n...   \n",
       "6      0  even my brother is not like to speak with me. ...   \n",
       "7      0  as per your request 'melle melle (oru minnamin...   \n",
       "8      1  winner!! as a valued network customer you have...   \n",
       "9      1  had your mobile 11 months or more? u r entitle...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [go, jurong, point, ,, crazy, .., available, b...  \n",
       "1           [ok, lar, ..., joking, wif, u, oni, ...]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3  [u, dun, say, early, hor, ..., u, c, already, ...  \n",
       "4  [nah, n't, think, goes, usf, ,, lives, around,...  \n",
       "5  [freemsg, hey, darling, 's, 3, week, 's, word,...  \n",
       "6  [even, brother, like, speak, ., treat, like, a...  \n",
       "7  [per, request, 'melle, melle, (, oru, minnamin...  \n",
       "8  [winner, !, !, valued, network, customer, sele...  \n",
       "9  [mobile, 11, months, ?, u, r, entitled, update...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming or Lemmatization**\n",
    "* Reduce words to their base or root form or to their dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_words(stopwords_tokenize_message):\n",
    "    \"\"\"\n",
    "    breaking words to a base or it's dictionary form\n",
    "    \"\"\"\n",
    "    stemmed_token = [stemmer.stem(word) for word in stopwords_tokenize_message]\n",
    "    return stemmed_token\n",
    "\n",
    "\n",
    "df['tokenized'] = df['tokenized'].apply(stemming_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, jurong, point, ,, crazi, .., avail, bugi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, n't, think, goe, usf, ,, live, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>[freemsg, hey, darl, 's, 3, week, 's, word, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>[even, brother, like, speak, ., treat, like, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>[per, request, 'mell, mell, (, oru, minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "      <td>[winner, !, !, valu, network, custom, select, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "      <td>[mobil, 11, month, ?, u, r, entitl, updat, lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>i'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>['m, gon, na, home, soon, n't, want, talk, stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>six chances to win cash! from 100 to 20,000 po...</td>\n",
       "      <td>[six, chanc, win, cash, !, 100, 20,000, pound,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent! you have won a 1 week free membership ...</td>\n",
       "      <td>[urgent, !, 1, week, free, membership, £100,00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>i've been searching for the right words to tha...</td>\n",
       "      <td>['ve, search, right, word, thank, breather, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>i have a date on sunday with will!!</td>\n",
       "      <td>[date, sunday, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>xxxmobilemovieclub: to use your credit, click ...</td>\n",
       "      <td>[xxxmobilemovieclub, :, use, credit, ,, click,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>oh k...i'm watching here:)</td>\n",
       "      <td>[oh, k, ..., 'm, watch, :, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>eh u remember how 2 spell his name... yes i di...</td>\n",
       "      <td>[eh, u, rememb, 2, spell, name, ..., ye, ., v,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>fine if thats the way u feel. thats the way ...</td>\n",
       "      <td>[fine, that, way, u, feel, ., that, way, got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>england v macedonia - dont miss the goals/team...</td>\n",
       "      <td>[england, v, macedonia, -, dont, miss, goals/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                            message  \\\n",
       "0       0  go until jurong point, crazy.. available only ...   \n",
       "1       0                      ok lar... joking wif u oni...   \n",
       "2       1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3       0  u dun say so early hor... u c already then say...   \n",
       "4       0  nah i don't think he goes to usf, he lives aro...   \n",
       "5       1  freemsg hey there darling it's been 3 week's n...   \n",
       "6       0  even my brother is not like to speak with me. ...   \n",
       "7       0  as per your request 'melle melle (oru minnamin...   \n",
       "8       1  winner!! as a valued network customer you have...   \n",
       "9       1  had your mobile 11 months or more? u r entitle...   \n",
       "10      0  i'm gonna be home soon and i don't want to tal...   \n",
       "11      1  six chances to win cash! from 100 to 20,000 po...   \n",
       "12      1  urgent! you have won a 1 week free membership ...   \n",
       "13      0  i've been searching for the right words to tha...   \n",
       "14      0                i have a date on sunday with will!!   \n",
       "15      1  xxxmobilemovieclub: to use your credit, click ...   \n",
       "16      0                         oh k...i'm watching here:)   \n",
       "17      0  eh u remember how 2 spell his name... yes i di...   \n",
       "18      0  fine if thats the way u feel. thats the way ...   \n",
       "19      1  england v macedonia - dont miss the goals/team...   \n",
       "\n",
       "                                            tokenized  \n",
       "0   [go, jurong, point, ,, crazi, .., avail, bugi,...  \n",
       "1              [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2   [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3   [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
       "4   [nah, n't, think, goe, usf, ,, live, around, t...  \n",
       "5   [freemsg, hey, darl, 's, 3, week, 's, word, ba...  \n",
       "6   [even, brother, like, speak, ., treat, like, a...  \n",
       "7   [per, request, 'mell, mell, (, oru, minnaminun...  \n",
       "8   [winner, !, !, valu, network, custom, select, ...  \n",
       "9   [mobil, 11, month, ?, u, r, entitl, updat, lat...  \n",
       "10  ['m, gon, na, home, soon, n't, want, talk, stu...  \n",
       "11  [six, chanc, win, cash, !, 100, 20,000, pound,...  \n",
       "12  [urgent, !, 1, week, free, membership, £100,00...  \n",
       "13  ['ve, search, right, word, thank, breather, .,...  \n",
       "14                               [date, sunday, !, !]  \n",
       "15  [xxxmobilemovieclub, :, use, credit, ,, click,...  \n",
       "16                      [oh, k, ..., 'm, watch, :, )]  \n",
       "17  [eh, u, rememb, 2, spell, name, ..., ye, ., v,...  \n",
       "18  [fine, that, way, u, feel, ., that, way, got...  \n",
       "19  [england, v, macedonia, -, dont, miss, goals/t...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "   ---------------------------------------- 0.0/6.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/6.8 MB 975.2 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.2/6.8 MB 1.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/6.8 MB 1.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.4/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.5/6.8 MB 1.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/6.8 MB 1.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.7/6.8 MB 1.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/6.8 MB 1.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.9/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.9/6.8 MB 1.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.1/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.2/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.3/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.4/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.4/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.5/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.5/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.5/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.8/6.8 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.9/6.8 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.9/6.8 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.9/6.8 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.0/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.0/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.1/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.1/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.2/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.2/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.2/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.5/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.6/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.6/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.7/6.8 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.7/6.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.8/6.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.8/6.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.9/6.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.9/6.8 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.1/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.1/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.2/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 3.2/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 3.3/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 3.3/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 3.4/6.8 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 3.6/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.7/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.8/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.9/6.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 4.0/6.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 4.0/6.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.1/6.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.1/6.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.1/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.2/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.2/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 4.3/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 4.3/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 4.3/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 4.4/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 4.4/6.8 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 4.5/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.6/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.6/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.7/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.7/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.7/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.8/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.9/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.0/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.1/6.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.2/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.3/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.4/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 5.4/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 5.5/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 5.5/6.8 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.6/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.6/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.7/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.7/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.9/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.9/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.0/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.0/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.1/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.4/6.8 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.5/6.8 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.5/6.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.7/6.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.8/6.8 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell checking and correction\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Function to correct spelling of a single message\n",
    "def correct_spelling(message):\n",
    "    return [spell.correction(word) if word in spell else word for word in message]\n",
    "\n",
    "# Apply the correction function to all messages in the DataFrame in batches\n",
    "batch_size = 1000\n",
    "num_batches = (len(df) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(df))\n",
    "    df.loc[start_idx:end_idx, \"tokenized\"] = df.loc[start_idx:end_idx, \"tokenized\"].apply(correct_spelling)\n",
    "\n",
    "# Join the corrected tokens back into a single string\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go jurong point , crazi .. avail bugi n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say earli hor ... u c alreadi say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah n't think goe usf , live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey darl 's 3 week 's word back ! 'd l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak . treat like aid patent .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>per request 'mell mell ( oru minnaminungint nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "      <td>winner ! ! valu network custom select receivea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "      <td>mobil 11 month ? u r entitl updat latest colou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  go until jurong point, crazy.. available only ...   \n",
       "1      0                      ok lar... joking wif u oni...   \n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      0  u dun say so early hor... u c already then say...   \n",
       "4      0  nah i don't think he goes to usf, he lives aro...   \n",
       "5      1  freemsg hey there darling it's been 3 week's n...   \n",
       "6      0  even my brother is not like to speak with me. ...   \n",
       "7      0  as per your request 'melle melle (oru minnamin...   \n",
       "8      1  winner!! as a valued network customer you have...   \n",
       "9      1  had your mobile 11 months or more? u r entitle...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  go jurong point , crazi .. avail bugi n great ...  \n",
       "1                      ok lar ... joke wif u oni ...  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3        u dun say earli hor ... u c alreadi say ...  \n",
       "4         nah n't think goe usf , live around though  \n",
       "5  freemsg hey darl 's 3 week 's word back ! 'd l...  \n",
       "6  even brother like speak . treat like aid patent .  \n",
       "7  per request 'mell mell ( oru minnaminungint nu...  \n",
       "8  winner ! ! valu network custom select receivea...  \n",
       "9  mobil 11 month ? u r entitl updat latest colou...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go jurong point , crazi .. avail bugi n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say earli hor ... u c alreadi say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah n't think goe usf , live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey darl 's 3 week 's word back ! 'd l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak . treat like aid patent .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>per request 'mell mell ( oru minnaminungint nu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  go until jurong point, crazy.. available only ...   \n",
       "1      0                      ok lar... joking wif u oni...   \n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      0  u dun say so early hor... u c already then say...   \n",
       "4      0  nah i don't think he goes to usf, he lives aro...   \n",
       "5      1  freemsg hey there darling it's been 3 week's n...   \n",
       "6      0  even my brother is not like to speak with me. ...   \n",
       "7      0  as per your request 'melle melle (oru minnamin...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  go jurong point , crazi .. avail bugi n great ...  \n",
       "1                      ok lar ... joke wif u oni ...  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3        u dun say earli hor ... u c alreadi say ...  \n",
       "4         nah n't think goe usf , live around though  \n",
       "5  freemsg hey darl 's 3 week 's word back ! 'd l...  \n",
       "6  even brother like speak . treat like aid patent .  \n",
       "7  per request 'mell mell ( oru minnaminungint nu...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces\n",
    "df['tokenized'] = df['tokenized'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    " # Remove non-standard characters (e.g., special symbols, non-printable characters)\n",
    "df['tokenized'] = df['tokenized'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our X & y\n",
    "X = df.drop(['label', 'message'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
